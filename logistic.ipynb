{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7ab102-d475-4de2-8d3b-5d582a48226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.4597 - loss: 1.0182 - val_accuracy: 0.5833 - val_loss: 1.0057\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6837 - loss: 0.9157 - val_accuracy: 0.6667 - val_loss: 0.9486\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7855 - loss: 0.8414 - val_accuracy: 0.6667 - val_loss: 0.8957\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7904 - loss: 0.7730 - val_accuracy: 0.6667 - val_loss: 0.8481\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7510 - loss: 0.7194 - val_accuracy: 0.6667 - val_loss: 0.8054\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8197 - loss: 0.6664 - val_accuracy: 0.6667 - val_loss: 0.7667\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8187 - loss: 0.6057 - val_accuracy: 0.6667 - val_loss: 0.7322\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8156 - loss: 0.5875 - val_accuracy: 0.7500 - val_loss: 0.7009\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8427 - loss: 0.5453 - val_accuracy: 0.7500 - val_loss: 0.6728\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8296 - loss: 0.5092 - val_accuracy: 0.7500 - val_loss: 0.6476\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7978 - loss: 0.5058 - val_accuracy: 0.8333 - val_loss: 0.6253\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7988 - loss: 0.4924 - val_accuracy: 0.8333 - val_loss: 0.6056\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8115 - loss: 0.4536 - val_accuracy: 0.8333 - val_loss: 0.5879\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8332 - loss: 0.4274 - val_accuracy: 0.8333 - val_loss: 0.5722\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8041 - loss: 0.4105 - val_accuracy: 0.8333 - val_loss: 0.5580\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7905 - loss: 0.4330 - val_accuracy: 0.8333 - val_loss: 0.5454\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8135 - loss: 0.4020 - val_accuracy: 0.8333 - val_loss: 0.5338\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8162 - loss: 0.4150 - val_accuracy: 0.8333 - val_loss: 0.5236\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8244 - loss: 0.3723 - val_accuracy: 0.8333 - val_loss: 0.5138\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8912 - loss: 0.3199 - val_accuracy: 0.8333 - val_loss: 0.5050\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8244 - loss: 0.3438 - val_accuracy: 0.8333 - val_loss: 0.4979\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8245 - loss: 0.3731 - val_accuracy: 0.9167 - val_loss: 0.4907\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8433 - loss: 0.3271 - val_accuracy: 0.9167 - val_loss: 0.4831\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8126 - loss: 0.3613 - val_accuracy: 0.9167 - val_loss: 0.4757\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8439 - loss: 0.3367 - val_accuracy: 0.9167 - val_loss: 0.4689\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8041 - loss: 0.3480 - val_accuracy: 0.9167 - val_loss: 0.4619\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8286 - loss: 0.3223 - val_accuracy: 0.9167 - val_loss: 0.4554\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8977 - loss: 0.2840 - val_accuracy: 0.9167 - val_loss: 0.4498\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8480 - loss: 0.3299 - val_accuracy: 0.9167 - val_loss: 0.4457\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8757 - loss: 0.3010 - val_accuracy: 0.9167 - val_loss: 0.4402\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8382 - loss: 0.3074 - val_accuracy: 0.9167 - val_loss: 0.4358\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8376 - loss: 0.3046 - val_accuracy: 0.9167 - val_loss: 0.4310\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8836 - loss: 0.2737 - val_accuracy: 0.9167 - val_loss: 0.4263\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8785 - loss: 0.2853 - val_accuracy: 0.9167 - val_loss: 0.4217\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8831 - loss: 0.2767 - val_accuracy: 0.9167 - val_loss: 0.4172\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8826 - loss: 0.2687 - val_accuracy: 0.9167 - val_loss: 0.4113\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8983 - loss: 0.2785 - val_accuracy: 0.9167 - val_loss: 0.4054\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8926 - loss: 0.2760 - val_accuracy: 0.9167 - val_loss: 0.3998\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9006 - loss: 0.2671 - val_accuracy: 0.9167 - val_loss: 0.3959\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9187 - loss: 0.2526 - val_accuracy: 0.9167 - val_loss: 0.3915\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8884 - loss: 0.2634 - val_accuracy: 0.9167 - val_loss: 0.3879\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9260 - loss: 0.2161 - val_accuracy: 0.9167 - val_loss: 0.3824\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9308 - loss: 0.2325 - val_accuracy: 0.9167 - val_loss: 0.3776\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9061 - loss: 0.2335 - val_accuracy: 0.9167 - val_loss: 0.3744\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8770 - loss: 0.2617 - val_accuracy: 0.9167 - val_loss: 0.3691\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9078 - loss: 0.2228 - val_accuracy: 0.9167 - val_loss: 0.3645\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9417 - loss: 0.2196 - val_accuracy: 0.9167 - val_loss: 0.3629\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9329 - loss: 0.2311 - val_accuracy: 0.9167 - val_loss: 0.3610\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9340 - loss: 0.2251 - val_accuracy: 0.9167 - val_loss: 0.3570\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9497 - loss: 0.2177 - val_accuracy: 0.9167 - val_loss: 0.3518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9667 - loss: 0.1707\n",
      "Neural Network Test accuracy: 0.9666666388511658\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.3704 - loss: 1.2743 - val_accuracy: 0.4167 - val_loss: 1.1239\n",
      "Epoch 2/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3355 - loss: 1.2999 - val_accuracy: 0.4167 - val_loss: 1.1148\n",
      "Epoch 3/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3361 - loss: 1.2941 - val_accuracy: 0.4167 - val_loss: 1.1059\n",
      "Epoch 4/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3492 - loss: 1.2768 - val_accuracy: 0.4167 - val_loss: 1.0971\n",
      "Epoch 5/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3617 - loss: 1.2287 - val_accuracy: 0.4167 - val_loss: 1.0884\n",
      "Epoch 6/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4039 - loss: 1.1825 - val_accuracy: 0.4167 - val_loss: 1.0798\n",
      "Epoch 7/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3571 - loss: 1.2437 - val_accuracy: 0.4167 - val_loss: 1.0715\n",
      "Epoch 8/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3508 - loss: 1.2156 - val_accuracy: 0.5000 - val_loss: 1.0633\n",
      "Epoch 9/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3977 - loss: 1.1684 - val_accuracy: 0.5000 - val_loss: 1.0552\n",
      "Epoch 10/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3707 - loss: 1.2054 - val_accuracy: 0.5833 - val_loss: 1.0473\n",
      "Epoch 11/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4145 - loss: 1.1307 - val_accuracy: 0.5833 - val_loss: 1.0394\n",
      "Epoch 12/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3957 - loss: 1.1369 - val_accuracy: 0.5833 - val_loss: 1.0315\n",
      "Epoch 13/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4124 - loss: 1.1457 - val_accuracy: 0.5833 - val_loss: 1.0237\n",
      "Epoch 14/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.3828 - loss: 1.1375 - val_accuracy: 0.5833 - val_loss: 1.0161\n",
      "Epoch 15/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3921 - loss: 1.1200 - val_accuracy: 0.5833 - val_loss: 1.0085\n",
      "Epoch 16/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4344 - loss: 1.0855 - val_accuracy: 0.5833 - val_loss: 1.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4381 - loss: 1.0746 - val_accuracy: 0.5833 - val_loss: 0.9937\n",
      "Epoch 18/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4553 - loss: 1.0525 - val_accuracy: 0.5833 - val_loss: 0.9866\n",
      "Epoch 19/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4486 - loss: 1.0602 - val_accuracy: 0.5833 - val_loss: 0.9794\n",
      "Epoch 20/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4122 - loss: 1.0523 - val_accuracy: 0.5833 - val_loss: 0.9725\n",
      "Epoch 21/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4340 - loss: 1.0674 - val_accuracy: 0.5833 - val_loss: 0.9656\n",
      "Epoch 22/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4642 - loss: 1.0111 - val_accuracy: 0.5833 - val_loss: 0.9588\n",
      "Epoch 23/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4956 - loss: 0.9894 - val_accuracy: 0.5833 - val_loss: 0.9521\n",
      "Epoch 24/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4414 - loss: 1.0102 - val_accuracy: 0.5833 - val_loss: 0.9455\n",
      "Epoch 25/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4795 - loss: 1.0148 - val_accuracy: 0.6667 - val_loss: 0.9391\n",
      "Epoch 26/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5093 - loss: 0.9511 - val_accuracy: 0.6667 - val_loss: 0.9327\n",
      "Epoch 27/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5020 - loss: 0.9641 - val_accuracy: 0.6667 - val_loss: 0.9264\n",
      "Epoch 28/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4853 - loss: 0.9668 - val_accuracy: 0.6667 - val_loss: 0.9203\n",
      "Epoch 29/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5223 - loss: 0.9439 - val_accuracy: 0.6667 - val_loss: 0.9142\n",
      "Epoch 30/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4650 - loss: 0.9554 - val_accuracy: 0.6667 - val_loss: 0.9082\n",
      "Epoch 31/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4880 - loss: 0.9234 - val_accuracy: 0.7500 - val_loss: 0.9023\n",
      "Epoch 32/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5354 - loss: 0.9285 - val_accuracy: 0.7500 - val_loss: 0.8965\n",
      "Epoch 33/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4902 - loss: 0.9445 - val_accuracy: 0.7500 - val_loss: 0.8909\n",
      "Epoch 34/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4860 - loss: 0.9266 - val_accuracy: 0.7500 - val_loss: 0.8853\n",
      "Epoch 35/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5366 - loss: 0.9000 - val_accuracy: 0.7500 - val_loss: 0.8798\n",
      "Epoch 36/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5382 - loss: 0.8842 - val_accuracy: 0.7500 - val_loss: 0.8744\n",
      "Epoch 37/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5081 - loss: 0.9061 - val_accuracy: 0.7500 - val_loss: 0.8692\n",
      "Epoch 38/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5722 - loss: 0.8698 - val_accuracy: 0.7500 - val_loss: 0.8639\n",
      "Epoch 39/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5576 - loss: 0.8607 - val_accuracy: 0.7500 - val_loss: 0.8587\n",
      "Epoch 40/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5682 - loss: 0.8719 - val_accuracy: 0.7500 - val_loss: 0.8537\n",
      "Epoch 41/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5817 - loss: 0.8424 - val_accuracy: 0.7500 - val_loss: 0.8487\n",
      "Epoch 42/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5964 - loss: 0.8401 - val_accuracy: 0.7500 - val_loss: 0.8438\n",
      "Epoch 43/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6142 - loss: 0.8319 - val_accuracy: 0.7500 - val_loss: 0.8390\n",
      "Epoch 44/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6571 - loss: 0.8274 - val_accuracy: 0.7500 - val_loss: 0.8343\n",
      "Epoch 45/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6368 - loss: 0.8143 - val_accuracy: 0.7500 - val_loss: 0.8296\n",
      "Epoch 46/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6603 - loss: 0.8041 - val_accuracy: 0.8333 - val_loss: 0.8250\n",
      "Epoch 47/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6353 - loss: 0.8028 - val_accuracy: 0.8333 - val_loss: 0.8205\n",
      "Epoch 48/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6520 - loss: 0.8087 - val_accuracy: 0.8333 - val_loss: 0.8160\n",
      "Epoch 49/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6432 - loss: 0.8158 - val_accuracy: 0.8333 - val_loss: 0.8116\n",
      "Epoch 50/50\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6640 - loss: 0.7944 - val_accuracy: 0.8333 - val_loss: 0.8073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6667 - loss: 0.7425\n",
      "Logistic Regression Test accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load and preprocess data (example: Iris dataset)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define and train a simple neural network\n",
    "model_nn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_nn.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "model_nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.1)\n",
    "\n",
    "# Evaluate the neural network\n",
    "test_loss_nn, test_accuracy_nn = model_nn.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Neural Network Test accuracy: {test_accuracy_nn}\")\n",
    "\n",
    "# Define and train logistic regression using TensorFlow\n",
    "model_lr = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, activation='softmax', input_shape=(4,))\n",
    "])\n",
    "\n",
    "model_lr.compile(optimizer='adam',\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "model_lr.fit(X_train_scaled, y_train, epochs=50, validation_split=0.1)\n",
    "\n",
    "# Evaluate logistic regression\n",
    "test_loss_lr, test_accuracy_lr = model_lr.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Logistic Regression Test accuracy: {test_accuracy_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6fe97e-07aa-4df4-9a51-7386c372048e",
   "metadata": {},
   "source": [
    "This code snippet demonstrates the use of TensorFlow to build and train two models on the Iris dataset: a simple neural network and a logistic regression model. The code covers data preparation, model definition, training, and evaluation. Here's a detailed explanation of each section:\n",
    "\n",
    "### 1. Importing Libraries\n",
    "- `import tensorflow as tf`: Imports TensorFlow, which is used to define and train the models.\n",
    "- `from sklearn.datasets import load_iris`: Imports the Iris dataset from scikit-learn, a classic dataset for classification tasks.\n",
    "- `from sklearn.model_selection import train_test_split`: Imports a function to split the dataset into training and testing sets.\n",
    "- `from sklearn.preprocessing import StandardScaler`: Imports a scaler to standardize the features.\n",
    "\n",
    "### 2. Load and Preprocess Data\n",
    "- `iris = load_iris()`: Loads the Iris dataset, which has 150 samples, each with 4 features, and 3 distinct classes (target values).\n",
    "- `X, y = iris.data, iris.target`: Separates the dataset into features `X` and labels `y`.\n",
    "- `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`: Splits the dataset into training and testing sets, with 80% for training and 20% for testing. The `random_state=42` ensures reproducibility.\n",
    "- `scaler = StandardScaler()`: Creates a `StandardScaler` object to standardize the features.\n",
    "- `X_train_scaled = scaler.fit_transform(X_train)`: Fits the scaler to the training data and transforms it, normalizing the features to have mean 0 and variance 1.\n",
    "- `X_test_scaled = scaler.transform(X_test)`: Transforms the testing data using the same scaler. This ensures that both training and testing data are scaled consistently.\n",
    "\n",
    "### 3. Define and Train a Simple Neural Network\n",
    "- `model_nn = tf.keras.Sequential([ ... ])`: Creates a sequential neural network model.\n",
    "  - `tf.keras.layers.Flatten(input_shape=(4,))`: Flattens the 4-feature input into a 1D array, preparing it for dense layers.\n",
    "  - `tf.keras.layers.Dense(128, activation='relu')`: Adds a dense (fully connected) layer with 128 units, using the ReLU activation function.\n",
    "  - `tf.keras.layers.Dropout(0.2)`: Adds a dropout layer to randomly drop 20% of the units during training, reducing overfitting.\n",
    "  - `tf.keras.layers.Dense(3, activation='softmax')`: Adds an output layer with 3 units (corresponding to the 3 classes in the Iris dataset), using the softmax activation function, which is appropriate for multi-class classification.\n",
    "- `model_nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])`: Compiles the neural network with:\n",
    "  - `optimizer='adam'`: Uses the Adam optimizer for training.\n",
    "  - `loss='sparse_categorical_crossentropy'`: Uses sparse categorical cross-entropy as the loss function, as the labels are not one-hot encoded.\n",
    "  - `metrics=['accuracy']`: Tracks accuracy as a performance metric during training.\n",
    "- `model_nn.fit(X_train_scaled, y_train, epochs=50, validation_split=0.1)`: Trains the neural network for 50 epochs, with 10% of the training data used for validation.\n",
    "\n",
    "### 4. Evaluate the Neural Network\n",
    "- `test_loss_nn, test_accuracy_nn = model_nn.evaluate(X_test_scaled, y_test)`: Evaluates the neural network's performance on the test set, returning the loss and accuracy.\n",
    "- `print(f\"Neural Network Test accuracy: {test_accuracy_nn}\")`: Prints the test accuracy to assess the model's performance.\n",
    "\n",
    "### 5. Define and Train Logistic Regression\n",
    "- `model_lr = tf.keras.Sequential([ ... ])`: Creates a simple logistic regression model.\n",
    "  - `tf.keras.layers.Dense(3, activation='softmax', input_shape=(4,))`: Adds a dense layer with 3 units and softmax activation. This layer serves as the logistic regression, directly mapping the 4-feature input to 3-class output.\n",
    "- `model_lr.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])`: Compiles the logistic regression model with the same settings as the neural network.\n",
    "- `model_lr.fit(X_train_scaled, y_train, epochs=50, validation_split=0.1)`: Trains the logistic regression model for 50 epochs, using 10% of the training data for validation.\n",
    "\n",
    "### 6. Evaluate Logistic Regression\n",
    "- `test_loss_lr, test_accuracy_lr = model_lr.evaluate(X_test_scaled, y_test)`: Evaluates the logistic regression model on the test set.\n",
    "- `print(f\"Logistic Regression Test accuracy: {test_accuracy_lr}\")`: Outputs the test accuracy to compare with the neural network's performance.\n",
    "\n",
    "### Summary\n",
    "This code snippet demonstrates how to build and train two different models using TensorFlow/Keras: a simple neural network with dense and dropout layers, and a logistic regression model. It uses the Iris dataset and applies standard preprocessing techniques, such as data scaling. The code trains both models and compares their accuracy on the test set, providing a simple example of multi-class classification with different model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b9dd6-a60f-4a7b-8ba3-831fb6af6edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
